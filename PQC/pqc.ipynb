{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aec56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end QNN training loop (Qiskit Estimator + SPSA), 8-qubit covariance-driven ansatz\n",
    "# - Data encoding: one pass RZ(x_i) -> RX(x_i)\n",
    "# - Trainable params: per-layer RY on each qubit + per-edge RZZ angles\n",
    "# - Readout: mean Z expectation across all qubits -> sigmoid -> BCE loss\n",
    "#\n",
    "# Requirements: qiskit >= 1.0\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from qiskit.circuit.library import RZZGate\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import Estimator\n",
    "\n",
    "\n",
    "# ---------- Utilities: covariance -> correlation graph ----------\n",
    "def covariance_to_corr(C: np.ndarray) -> np.ndarray:\n",
    "    d = np.sqrt(np.diag(C))\n",
    "    R = C / np.outer(d, d)\n",
    "    np.fill_diagonal(R, 0.0)\n",
    "    return np.clip(R, -1.0, 1.0)\n",
    "\n",
    "def sparsify_corr(R: np.ndarray, threshold: float = 0.2) -> np.ndarray:\n",
    "    M = R.copy()\n",
    "    M[np.abs(M) < threshold] = 0.0\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "    return M\n",
    "\n",
    "def edge_list(W: np.ndarray) -> List[Tuple[int,int,float]]:\n",
    "    n = W.shape[0]\n",
    "    return [(i, j, W[i, j]) for i, j in combinations(range(n), 2) if W[i, j] != 0.0]\n",
    "\n",
    "\n",
    "# ---------- Model/Params container ----------\n",
    "@dataclass\n",
    "class QNN:\n",
    "    circuit: QuantumCircuit\n",
    "    n: int\n",
    "    layers: int\n",
    "    edges: List[Tuple[int,int,float]]\n",
    "    # data parameters (bound per-sample, not optimized)\n",
    "    phi_z: ParameterVector         # length n\n",
    "    phi_x: ParameterVector         # length n\n",
    "    # trainable parameters\n",
    "    theta_ry: List[ParameterVector]                 # per-layer length n\n",
    "    theta_edge: Dict[Tuple[int,int,int], Parameter] # (ell,i,j) -> Parameter\n",
    "\n",
    "\n",
    "# ---------- Build the QNN ----------\n",
    "def build_qnn(C: np.ndarray, layers: int = 2, edge_threshold: float = 0.2) -> QNN:\n",
    "    \"\"\"\n",
    "    U(x; θ) for n=len(C):\n",
    "      - Encode x with ∏_i RZ(x_i) RX(x_i)\n",
    "      - For each layer:\n",
    "          ∏_i RY(θ_ry[ell,i])\n",
    "          ∏_(i<j) RZZ(θ_edge[ell,i,j] * w_ij)\n",
    "    Readout: mean Z expectation over all qubits (done outside circuit).\n",
    "    \"\"\"\n",
    "    n = C.shape[0]\n",
    "    R = covariance_to_corr(C)\n",
    "    W = sparsify_corr(R, edge_threshold)\n",
    "    E = edge_list(W)\n",
    "\n",
    "    qc = QuantumCircuit(n, name=\"CovGraphQNN\")\n",
    "\n",
    "    # Data parameters (bound per sample)\n",
    "    phi_z = ParameterVector(\"φz\", n)\n",
    "    phi_x = ParameterVector(\"φx\", n)\n",
    "    for q in range(n):\n",
    "        qc.rz(phi_z[q], q)\n",
    "        qc.rx(phi_x[q], q)\n",
    "\n",
    "    # Trainable parameters\n",
    "    theta_ry: List[ParameterVector] = []\n",
    "    theta_edge: Dict[Tuple[int,int,int], Parameter] = {}\n",
    "    for ell in range(layers):\n",
    "        pv = ParameterVector(f\"θ_ry_l{ell}\", n)\n",
    "        theta_ry.append(pv)\n",
    "        # single-qubit trainables\n",
    "        for q in range(n):\n",
    "            qc.ry(pv[q], q)\n",
    "        # edge-wise ZZ\n",
    "        for (i, j, w) in E:\n",
    "            p = Parameter(f\"θ_e_l{ell}_{i}_{j}\")\n",
    "            theta_edge[(ell, i, j)] = p\n",
    "            qc.append(RZZGate(p * w), [i, j])\n",
    "\n",
    "    return QNN(\n",
    "        circuit=qc,\n",
    "        n=n,\n",
    "        layers=layers,\n",
    "        edges=E,\n",
    "        phi_z=phi_z,\n",
    "        phi_x=phi_x,\n",
    "        theta_ry=theta_ry,\n",
    "        theta_edge=theta_edge\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- Readout observable: mean Z over all qubits ----------\n",
    "def mean_z_observable(n: int) -> SparsePauliOp:\n",
    "    # (1/n) * sum_i Z_i  == average magnetization\n",
    "    paulis = []\n",
    "    coeffs = []\n",
    "    for i in range(n):\n",
    "        z_str = ['I'] * n\n",
    "        z_str[i] = 'Z'\n",
    "        # Reverse because rightmost char applies to qubit 0 in Qiskit little-endian convention\n",
    "        paulis.append(''.join(reversed(z_str)))\n",
    "        coeffs.append(1.0 / n)\n",
    "    return SparsePauliOp.from_list(list(zip(paulis, coeffs)))\n",
    "\n",
    "\n",
    "# ---------- Loss & metrics ----------\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def binary_cross_entropy(logit, y):\n",
    "    p = sigmoid(logit)\n",
    "    eps = 1e-10\n",
    "    return -(y * np.log(p + eps) + (1 - y) * np.log(1 - p + eps))\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    preds = (sigmoid(logits) >= 0.5).astype(int)\n",
    "    return float(np.mean(preds == y))\n",
    "\n",
    "\n",
    "# ---------- Parameter packing helpers ----------\n",
    "def init_theta(qnn: QNN, seed: int = 7, scale: float = 0.2) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # concatenate [all θ_ry; all θ_edge]\n",
    "    ry_total = qnn.layers * qnn.n\n",
    "    edge_total = len(qnn.edges) * qnn.layers\n",
    "    theta = np.zeros(ry_total + edge_total)\n",
    "    theta[:ry_total] = rng.normal(0, scale, size=ry_total)\n",
    "    theta[ry_total:] = rng.normal(0, scale, size=edge_total)\n",
    "    return theta\n",
    "\n",
    "def unpack_theta(qnn: QNN, theta: np.ndarray):\n",
    "    \"\"\"Return dict mapping Parameter -> value.\"\"\"\n",
    "    bind = {}\n",
    "    idx = 0\n",
    "    # θ_ry\n",
    "    for ell in range(qnn.layers):\n",
    "        for q in range(qnn.n):\n",
    "            bind[qnn.theta_ry[ell][q]] = float(theta[idx]); idx += 1\n",
    "    # θ_edge in fixed (ell, i, j) order for reproducibility\n",
    "    for ell in range(qnn.layers):\n",
    "        for (i, j, _) in qnn.edges:\n",
    "            bind[qnn.theta_edge[(ell, i, j)]] = float(theta[idx]); idx += 1\n",
    "    return bind\n",
    "\n",
    "def data_binding(qnn: QNN, x: np.ndarray):\n",
    "    \"\"\"Bind φz_i=x_i, φx_i=x_i (you can rescale if you like).\"\"\"\n",
    "    bind = {}\n",
    "    for i in range(qnn.n):\n",
    "        bind[qnn.phi_z[i]] = float(x[i])\n",
    "        bind[qnn.phi_x[i]] = float(x[i])\n",
    "    return bind\n",
    "\n",
    "\n",
    "# ---------- Forward pass ----------\n",
    "def forward_logits(estimator: Estimator, qnn: QNN, obs: SparsePauliOp,\n",
    "                   X: np.ndarray, theta: np.ndarray, shots: int = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns model logits for each x in X:\n",
    "      logit(x) = <mean Z> (no extra linear head; simple and stable)\n",
    "    \"\"\"\n",
    "    theta_bind = unpack_theta(qnn, theta)\n",
    "    circuits = []\n",
    "    observables = []\n",
    "    for x in X:\n",
    "        param_bind = {**theta_bind, **data_binding(qnn, x)}\n",
    "        circuits.append(qnn.circuit.assign_parameters(param_bind))\n",
    "        observables.append(obs)\n",
    "\n",
    "    run_opts = {} if shots is None else {\"shots\": shots}\n",
    "    res = estimator.run(\n",
    "        circuits=circuits,\n",
    "        observables=observables,\n",
    "        parameter_values=None,\n",
    "        **run_opts\n",
    "    ).result()\n",
    "    logits = np.array(res.values, dtype=float)\n",
    "    return logits\n",
    "\n",
    "\n",
    "# ---------- SPSA optimizer ----------\n",
    "@dataclass\n",
    "class SPSAConfig:\n",
    "    maxiter: int = 200\n",
    "    a: float = 0.05\n",
    "    c: float = 0.1\n",
    "    alpha: float = 0.602\n",
    "    gamma: float = 0.101\n",
    "    seed: int = 123\n",
    "\n",
    "def spsa_schedule(cfg: SPSAConfig, k: int):\n",
    "    ak = cfg.a / ((k + 1) ** cfg.alpha)\n",
    "    ck = cfg.c / ((k + 1) ** cfg.gamma)\n",
    "    return ak, ck\n",
    "\n",
    "def spsa_step(theta: np.ndarray, grad_est: np.ndarray, ak: float):\n",
    "    return theta - ak * grad_est\n",
    "\n",
    "def estimate_gradient_spsa(estimator: Estimator, qnn: QNN, obs: SparsePauliOp,\n",
    "                           X: np.ndarray, y: np.ndarray, theta: np.ndarray,\n",
    "                           ck: float, rng: np.random.Generator, shots: int = None) -> np.ndarray:\n",
    "    # Bernoulli ±1 perturbation\n",
    "    delta = rng.choice([-1.0, 1.0], size=theta.shape)\n",
    "    theta_plus  = theta + ck * delta\n",
    "    theta_minus = theta - ck * delta\n",
    "\n",
    "    # Forward passes\n",
    "    logits_plus  = forward_logits(estimator, qnn, obs, X, theta_plus,  shots=shots)\n",
    "    logits_minus = forward_logits(estimator, qnn, obs, X, theta_minus, shots=shots)\n",
    "\n",
    "    # Losses\n",
    "    Lp = np.mean([binary_cross_entropy(lp, yi) for lp, yi in zip(logits_plus,  y)])\n",
    "    Lm = np.mean([binary_cross_entropy(lm, yi) for lm, yi in zip(logits_minus, y)])\n",
    "\n",
    "    # SPSA gradient estimate (element-wise)\n",
    "    ghat = (Lp - Lm) / (2.0 * ck) * (1.0 / delta)\n",
    "    return ghat\n",
    "\n",
    "\n",
    "# ---------- Training loop ----------\n",
    "def train_qnn(C: np.ndarray, X: np.ndarray, y: np.ndarray,\n",
    "              layers: int = 2, edge_threshold: float = 0.2,\n",
    "              shots: int = None,  # set to an int (e.g., 4000) for sampling; None -> exact\n",
    "              spsa_cfg: SPSAConfig = SPSAConfig()):\n",
    "    \"\"\"\n",
    "    Returns: (theta_best, history, qnn, obs)\n",
    "    \"\"\"\n",
    "    assert X.shape[1] == C.shape[0], \"Feature dimension must match covariance size.\"\n",
    "    assert set(np.unique(y)).issubset({0, 1}), \"Binary labels expected (0/1).\"\n",
    "\n",
    "    qnn = build_qnn(C, layers=layers, edge_threshold=edge_threshold)\n",
    "    obs = mean_z_observable(qnn.n)\n",
    "    est = Estimator()  # choose backend via Estimator(options=...) if desired\n",
    "\n",
    "    # Init params\n",
    "    theta = init_theta(qnn, seed=7)\n",
    "    rng = np.random.default_rng(spsa_cfg.seed)\n",
    "    best_theta = theta.copy()\n",
    "\n",
    "    # Track\n",
    "    history = {\"loss\": [], \"acc\": []}\n",
    "\n",
    "    for k in range(spsa_cfg.maxiter):\n",
    "        ak, ck = spsa_schedule(spsa_cfg, k)\n",
    "\n",
    "        # Grad estimate\n",
    "        ghat = estimate_gradient_spsa(est, qnn, obs, X, y, theta, ck, rng, shots=shots)\n",
    "\n",
    "        # Step\n",
    "        theta = spsa_step(theta, ghat, ak)\n",
    "\n",
    "        # Eval\n",
    "        logits = forward_logits(est, qnn, obs, X, theta, shots=shots)\n",
    "        loss = float(np.mean([binary_cross_entropy(li, yi) for li, yi in zip(logits, y)]))\n",
    "        accu = accuracy(logits, y)\n",
    "\n",
    "        history[\"loss\"].append(loss)\n",
    "        history[\"acc\"].append(accu)\n",
    "\n",
    "        # Keep best by loss\n",
    "        if loss <= min(history[\"loss\"]):\n",
    "            best_theta = theta.copy()\n",
    "\n",
    "        # Simple progress print (every 10 iters)\n",
    "        if (k + 1) % 10 == 0 or k == 0:\n",
    "            print(f\"iter {k+1:4d} | loss {loss:.4f} | acc {accu:.3f}\")\n",
    "\n",
    "    return best_theta, history, qnn, obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ceb10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/correlation_matrix.csv')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "data = df.to_numpy()\n",
    "\n",
    "df = pd.read_csv('../Data/X_train_scaled.csv')\n",
    "df = df.drop(df.columns[-1],axis = 1)\n",
    "X = df.to_numpy()\n",
    "\n",
    "df = pd.read_excel('../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx')\n",
    "Y = df['ef_binary'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed45a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3963739/1592201083.py:243: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  est = Estimator()  # choose backend via Estimator(options=...) if desired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    1 | loss 1.1157 | acc 0.108\n",
      "iter   10 | loss 1.1122 | acc 0.108\n",
      "iter   20 | loss 1.1113 | acc 0.108\n",
      "iter   30 | loss 1.1108 | acc 0.108\n",
      "iter   40 | loss 1.1103 | acc 0.108\n",
      "iter   50 | loss 1.1101 | acc 0.108\n",
      "iter   60 | loss 1.1096 | acc 0.108\n",
      "iter   70 | loss 1.1093 | acc 0.108\n",
      "iter   80 | loss 1.1090 | acc 0.108\n",
      "iter   90 | loss 1.1085 | acc 0.108\n",
      "iter  100 | loss 1.1082 | acc 0.108\n"
     ]
    }
   ],
   "source": [
    "C = data\n",
    "best_theta, hist, qnn, obs = train_qnn(\n",
    "    C, X, Y, layers=2, edge_threshold=0.25,\n",
    "    shots=None,  # set to an int to mimic hardware sampling\n",
    "    spsa_cfg=SPSAConfig(maxiter=100, a=0.08, c=0.15)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3595ebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3963739/1961881304.py:2: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  est = Estimator()  # choose backend via Estimator(options=...) if desired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation labels not found; printed predictions only.\n",
      "Validation predictions (first 10): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Test predictions (first 10): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# ---- Validation / Test ----\n",
    "est = Estimator()  # choose backend via Estimator(options=...) if desired\n",
    "\n",
    "VAL_CSV  = \"../Data/X_val_scaled.csv\"\n",
    "TEST_CSV = \"../Data/X_test_scaled.csv\"\n",
    "FEATURE_COLS = None  # or None to use all-but-last\n",
    "LABEL_COL = \"label\"  # set to your actual label column if present\n",
    "\n",
    "def load_xy(csv_path, feature_cols, label_col):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if feature_cols is None:\n",
    "        X = df.iloc[:, :-1].to_numpy()\n",
    "        y = df.iloc[:, -1].to_numpy().astype(int) if (label_col in df.columns) else None\n",
    "    else:\n",
    "        X = df[feature_cols].to_numpy()\n",
    "        y = df[label_col].to_numpy().astype(int) if (label_col in df.columns) else None\n",
    "    return X, y\n",
    "\n",
    "# ---- Load val (already scaled) ----\n",
    "Xva, yva = load_xy(VAL_CSV, FEATURE_COLS, LABEL_COL)\n",
    "\n",
    "# ---- Inference on validation ----\n",
    "val_logits = forward_logits(est, qnn, obs, Xva, best_theta, shots=None)\n",
    "val_probs  = 1.0 / (1.0 + np.exp(-val_logits))\n",
    "val_pred   = (val_probs >= 0.5).astype(int)\n",
    "\n",
    "# ---- Metrics (requires labels present in val CSV) ----\n",
    "if yva is not None:\n",
    "    acc = float(np.mean(val_pred == yva))\n",
    "    tp = int(np.sum((val_pred == 1) & (yva == 1)))\n",
    "    fp = int(np.sum((val_pred == 1) & (yva == 0)))\n",
    "    fn = int(np.sum((val_pred == 0) & (yva == 1)))\n",
    "    prec = tp / (tp + fp + 1e-12)\n",
    "    rec  = tp / (tp + fn + 1e-12)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "    print(f\"Validation | acc={acc:.3f}  prec={prec:.3f}  rec={rec:.3f}  f1={f1:.3f}\")\n",
    "else:\n",
    "    print(\"Validation labels not found; printed predictions only.\")\n",
    "    print(\"Validation predictions (first 10):\", val_pred[:10].tolist())\n",
    "\n",
    "# ---- Optional: Test set (no labels expected) ----\n",
    "if TEST_CSV is not None:\n",
    "    Xte, yte = load_xy(TEST_CSV, FEATURE_COLS, LABEL_COL)  # yte may be None\n",
    "    test_logits = forward_logits(est, qnn, obs, Xte, best_theta, shots=None)\n",
    "    test_probs  = 1.0 / (1.0 + np.exp(-test_logits))\n",
    "    test_pred   = (test_probs >= 0.5).astype(int)\n",
    "    print(\"Test predictions (first 10):\", test_pred[:10].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0230042c-b8d2-427f-b03a-81925796b642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
