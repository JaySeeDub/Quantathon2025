{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_definitions import BinaryDNN_classical\n",
    "import torch\n",
    "from utils.imports import *\n",
    "from utils.Preprocessing import *\n",
    "from utils.Helper import *\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DNN = BinaryDNN_classical().to(device)\n",
    "# load_path = \"models/Binary_DNN_\" # Path to load model\n",
    "load_path = \"checkpoints/Binary_DNN_FULLENT_AUC.6993.1011_0915.pt\"\n",
    "# load_path = \"models/DNN_model_best_valLoss.pt\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n",
    "    \n",
    "print(f\"Loaded model from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bce587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.Preprocessing import Preprocess, ClassificationDataset, DataLoader\n",
    "TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "VALIDATION_FILE = '../Data/2025-Quantum-Tornado-validation_data-160-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "# Define variable and dataset\n",
    "batch_size = 64\n",
    "lr = 1e-2\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'binary')\n",
    "\n",
    "print(y_test[:])\n",
    "print(y_train[:])\n",
    "print(y_val[:])\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81347861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set model to evaluation mode ---\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.Helper import plot_confusion_matrix\n",
    "DNN.eval()\n",
    "\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).float().unsqueeze(-1)\n",
    "\n",
    "        outputs = DNN(features)\n",
    "        preds = (outputs > 0.5).float()\n",
    "\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_outputs.append(outputs.cpu())\n",
    "\n",
    "# --- Concatenate all batches ---\n",
    "all_targets = torch.cat(all_targets).squeeze().long().numpy()  # integers 0/1\n",
    "all_preds = torch.cat(all_preds).squeeze().long().numpy()\n",
    "all_outputs = torch.cat(all_outputs).squeeze().numpy()             # floats in [0,1]\n",
    "\n",
    "# --- Sanity check ---\n",
    "print(all_targets.shape, all_preds.shape, all_outputs.shape)\n",
    "print(np.unique(all_targets))  # should be [0,1]\n",
    "\n",
    "# --- Compute Metrics ---\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "auc_score = roc_auc_score(all_targets, all_outputs)  # should work now\n",
    "f1 = f1_score(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "# Critical Success Index (CSI)\n",
    "tp = cm[1,1]\n",
    "fn = cm[1,0]\n",
    "fp = cm[0,1]\n",
    "csi = tp / (tp + fn + fp)\n",
    "\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}, CSI: {csi:.4f}\")\n",
    "\n",
    "# --- Plot Confusion Matrix ---\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- Plot ROC Curve ---\n",
    "fpr, tpr, thresholds = roc_curve(all_targets, all_outputs)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}', color='blue')\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'multiclass')\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_definitions import MultiClassDNN_classical\n",
    "\n",
    "DNN = MultiClassDNN_classical().to(device)\n",
    "\n",
    "load_path = \"checkpoints/Multiclass_DNN_3Layer_AUC.8.1011_1012.pt\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n",
    "\n",
    "DNN.eval()\n",
    "all_targets, all_preds, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).long()\n",
    "        outputs = DNN(features)\n",
    "        \n",
    "        if outputs.shape[1] == 1:\n",
    "            # Binary case\n",
    "            probs = torch.sigmoid(outputs).squeeze(-1)\n",
    "            preds = (probs > 0.5).long()\n",
    "        else:\n",
    "            # Multiclass case\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_probs.append(probs.cpu())\n",
    "\n",
    "# Concatenate\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "if outputs.shape[1] == 1:\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    auc_score = roc_auc_score(all_targets, all_probs)\n",
    "    csi = cm[1,1] / (cm[1,1] + cm[1,0] + cm[0,1])\n",
    "else:\n",
    "    num_classes = outputs.shape[1]\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_targets], all_probs, multi_class='ovr')\n",
    "    csi = []\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i,i]\n",
    "        fn = cm[i,:].sum() - tp\n",
    "        fp = cm[:,i].sum() - tp\n",
    "        csi.append(tp / (tp + fn + fp) if (tp+fn+fp)>0 else 0)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "if outputs.shape[1] > 1:\n",
    "    for i, c in enumerate(csi):\n",
    "        print(f\"Class {i} CSI: {c:.4f}\")\n",
    "else:\n",
    "    print(f\"CSI: {csi:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "plt.figure(figsize=(7,6))\n",
    "if outputs.shape[1] == 1:\n",
    "    fpr, tpr, _ = roc_curve(all_targets, all_probs)\n",
    "    plt.plot(fpr, tpr, label=f'AUC={auc_score:.4f}')\n",
    "else:\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve((all_targets==i).astype(int), all_probs[:,i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# CSI bar for multiclass\n",
    "if outputs.shape[1] > 1:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar([f'Class {i}' for i in range(num_classes)], csi, color='green')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title('CSI per Class')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3783bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "VALIDATION_FILE = '../Data/2025-Quantum-Tornado-validation_data-160-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "# Quantum augmented datasets using random shadows\n",
    "EXTRA_TRAIN = \"../Data/36_featuresXY_train_QuantumLayers3.csv\"\n",
    "EXTRA_TEST  = \"../Data/36_featuresXY_test_QuantumLayers3.csv\"\n",
    "EXTRA_VALID = \"../Data/36_featuresXY_val_QuantumLayers3.csv\"\n",
    "\n",
    "# Extra features\n",
    "extra_train_df = pd.read_csv(EXTRA_TRAIN)\n",
    "extra_test_df = pd.read_csv(EXTRA_TEST)\n",
    "extra_valid_df = pd.read_csv(EXTRA_VALID)\n",
    "\n",
    "# Drop first column by index\n",
    "extra_train_df = extra_train_df.drop(extra_train_df.columns[0], axis=1)\n",
    "extra_test_df = extra_test_df.drop(extra_test_df.columns[0], axis=1)\n",
    "extra_valid_df = extra_valid_df.drop(extra_valid_df.columns[0], axis=1)\n",
    "\n",
    "# Concatenate extra features (axis=1 for columns)\n",
    "df_train = pd.concat([df_train, extra_train_df], axis=1)\n",
    "df_test  = pd.concat([df_test, extra_test_df], axis=1)\n",
    "df_val  = pd.concat([df_val, extra_valid_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'binary')\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_definitions import BinaryDNN_Hybrid\n",
    "DNN = BinaryDNN_Hybrid().to(device)\n",
    "\n",
    "load_path = \"checkpoints/Binary_DNN_FULLENT_AUC.6993.1011_1042.pt\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc797a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set model to evaluation mode ---\n",
    "DNN.eval()\n",
    "\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).float().unsqueeze(-1)\n",
    "\n",
    "        outputs = DNN(features)\n",
    "        preds = (outputs > 0.5).float()\n",
    "\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_outputs.append(outputs.cpu())\n",
    "\n",
    "# --- Concatenate all batches ---\n",
    "all_targets = torch.cat(all_targets).squeeze().long().numpy()  # integers 0/1\n",
    "all_preds = torch.cat(all_preds).squeeze().long().numpy()\n",
    "all_outputs = torch.cat(all_outputs).squeeze().numpy()             # floats in [0,1]\n",
    "\n",
    "# --- Sanity check ---\n",
    "print(all_targets.shape, all_preds.shape, all_outputs.shape)\n",
    "print(np.unique(all_targets))  # should be [0,1]\n",
    "\n",
    "# --- Compute Metrics ---\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "auc_score = roc_auc_score(all_targets, all_outputs)  # should work now\n",
    "f1 = f1_score(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "# Critical Success Index (CSI)\n",
    "tp = cm[1,1]\n",
    "fn = cm[1,0]\n",
    "fp = cm[0,1]\n",
    "csi = tp / (tp + fn + fp)\n",
    "\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}, CSI: {csi:.4f}\")\n",
    "\n",
    "# --- Plot Confusion Matrix ---\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- Plot ROC Curve ---\n",
    "fpr, tpr, thresholds = roc_curve(all_targets, all_outputs)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}', color='blue')\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "VALIDATION_FILE = '../Data/2025-Quantum-Tornado-validation_data-160-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "if True:\n",
    "    # Quantum augmented datasets using random shadows\n",
    "    EXTRA_TRAIN = \"../Data/36_featuresXY_train_QuantumLayers3.csv\"\n",
    "    EXTRA_TEST  = \"../Data/36_featuresXY_test_QuantumLayers3.csv\"\n",
    "    EXTRA_VALID = \"../Data/36_featuresXY_val_QuantumLayers3.csv\"\n",
    "    \n",
    "    # Extra features\n",
    "    extra_train_df = pd.read_csv(EXTRA_TRAIN)\n",
    "    extra_test_df = pd.read_csv(EXTRA_TEST)\n",
    "    extra_valid_df = pd.read_csv(EXTRA_VALID)\n",
    "    \n",
    "    # Drop first column by index\n",
    "    extra_train_df = extra_train_df.drop(extra_train_df.columns[0], axis=1)\n",
    "    extra_test_df = extra_test_df.drop(extra_test_df.columns[0], axis=1)\n",
    "    extra_valid_df = extra_valid_df.drop(extra_valid_df.columns[0], axis=1)\n",
    "    \n",
    "    # Concatenate extra features (axis=1 for columns)\n",
    "    df_train = pd.concat([df_train, extra_train_df], axis=1)\n",
    "    df_test  = pd.concat([df_test, extra_test_df], axis=1)\n",
    "    df_val  = pd.concat([df_val, extra_valid_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_definitions import MulticlassDNN_Hybrid\n",
    "\n",
    "DNN = MulticlassDNN_Hybrid().to(device)\n",
    "\n",
    "\n",
    "load_path = \"checkpoints/Multiclass_DNN_3Layer_AUC.8.best_1011_1053.pt\"\n",
    "\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n",
    "    \n",
    "print(f\"Loaded model from {load_path}\")\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'multiclass')\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(y_test[:])\n",
    "print(y_train[:])\n",
    "print(y_val[:])\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45030e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets, all_preds, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).long()\n",
    "        outputs = DNN(features)\n",
    "        \n",
    "        if outputs.shape[1] == 1:\n",
    "            # Binary case\n",
    "            probs = torch.sigmoid(outputs).squeeze(-1)\n",
    "            preds = (probs > 0.5).long()\n",
    "        else:\n",
    "            # Multiclass case\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_probs.append(probs.cpu())\n",
    "\n",
    "# Concatenate\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "if outputs.shape[1] == 1:\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    auc_score = roc_auc_score(all_targets, all_probs)\n",
    "    csi = cm[1,1] / (cm[1,1] + cm[1,0] + cm[0,1])\n",
    "else:\n",
    "    num_classes = outputs.shape[1]\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_targets], all_probs, multi_class='ovr')\n",
    "    csi = []\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i,i]\n",
    "        fn = cm[i,:].sum() - tp\n",
    "        fp = cm[:,i].sum() - tp\n",
    "        csi.append(tp / (tp + fn + fp) if (tp+fn+fp)>0 else 0)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "if outputs.shape[1] > 1:\n",
    "    for i, c in enumerate(csi):\n",
    "        print(f\"Class {i} CSI: {c:.4f}\")\n",
    "else:\n",
    "    print(f\"CSI: {csi:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "plt.figure(figsize=(7,6))\n",
    "if outputs.shape[1] == 1:\n",
    "    fpr, tpr, _ = roc_curve(all_targets, all_probs)\n",
    "    plt.plot(fpr, tpr, label=f'AUC={auc_score:.4f}')\n",
    "else:\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve((all_targets==i).astype(int), all_probs[:,i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Data paths\n",
    "TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "VALIDATION_FILE = '../Data/2025-Quantum-Tornado-validation_data-160-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "# Quantum device and parameters\n",
    "n_qubits = 8\n",
    "n_layers = 1\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Using Random Layers PQC\n",
    "USE_RANDOM = True\n",
    "\n",
    "if USE_RANDOM:\n",
    "    # RandomLayers expects shape (n_layers, n_rotations_per_layer)\n",
    "    # For 8 qubits, each layer typically has 3 * 8 = 24 rotations\n",
    "    rand_params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits * 3))\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "    def quantum_feature_embedding(f, phi):\n",
    "        qml.AngleEmbedding(features=f, wires=range(n_qubits))\n",
    "        RandomLayers(phi, wires=range(n_qubits), seed=6)\n",
    "        return qml.state()  # returns 2**n_qubits = 256-dim statevector\n",
    "\n",
    "# Using Strongly Entangling Layers\n",
    "else:\n",
    "    # StronglyEntanglingLayers expects shape (n_layers, n_wires, 3)\n",
    "    rand_params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits, 3))\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "    def quantum_feature_embedding(f, phi):\n",
    "        qml.AngleEmbedding(features=f, wires=range(n_qubits))\n",
    "        qml.StronglyEntanglingLayers(weights=phi, wires=range(n_qubits))\n",
    "        return qml.state()\n",
    "\n",
    "# Batched embedding helper\n",
    "def quantum_feature_embedding_batch(x_batch, phi, device=\"cuda\"):\n",
    "    \"\"\"Apply QNode to batch of inputs -> (B, 256)\"\"\"\n",
    "    outputs = []\n",
    "    phi = phi.detach().cpu()\n",
    "    for x in x_batch:\n",
    "        result = quantum_feature_embedding(x.detach().cpu(), phi)\n",
    "        outputs.append(result.real.to(device))\n",
    "    return torch.stack(outputs)\n",
    "\n",
    "# Test single example\n",
    "state = quantum_feature_embedding(\n",
    "    torch.tensor([1/4] * n_qubits, dtype=torch.float32),\n",
    "    torch.tensor(rand_params, dtype=torch.float32)\n",
    ")\n",
    "print(\"Single state shape:\", state.shape)  # (256,)\n",
    "\n",
    "# Test batch\n",
    "sample = torch.randn(16, n_qubits)\n",
    "phi_tensor = torch.tensor(rand_params, dtype=torch.float32)\n",
    "output = quantum_feature_embedding_batch(sample, phi_tensor, device = device)\n",
    "print(\"Batch output shape:\", output.shape)  # (16, 256)\n",
    "\n",
    "# Torch module for integration\n",
    "class QuantumFeatureEmbeddingBatch(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.phi = nn.Parameter(torch.tensor(\n",
    "            np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits * 3)), \n",
    "            dtype=torch.float32\n",
    "        ))\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        outputs = []\n",
    "        phi = self.phi.detach().cpu()\n",
    "        for x in x_batch:\n",
    "            result = quantum_feature_embedding(x.detach().cpu(), phi)\n",
    "            outputs.append(result.real.to(self.device))\n",
    "        return torch.stack(outputs)\n",
    "\n",
    "# Visualize\n",
    "qml.drawer.use_style('pennylane')\n",
    "fig, ax = qml.draw_mpl(quantum_feature_embedding, level=\"device\")(f=[1/4]*n_qubits, phi=rand_params)\n",
    "fig.show()\n",
    "plt.savefig('vlad.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25619a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Binary DN with Quantum Random Layer feature encoder\n",
    "class BinaryPQC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encodes features from dataset\n",
    "        self.feature_encoder = QuantumFeatureEmbeddingBatch()\n",
    "\n",
    "        # Classifies based on encoded features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        feats_encoded = self.feature_encoder(features)\n",
    "        class_probs = self.classifier(feats_encoded.float())\n",
    "\n",
    "        return class_probs  # Shape: (batch_size, 1)\n",
    "    \n",
    "DNN = BinaryPQC().to(device)\n",
    "    \n",
    "load_path = \"checkpoints/DNN_model_best_accuracy.pt\" # Path to load model\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(load_path, map_location=device)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n",
    "    \n",
    "print(f\"Loaded model from {load_path}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'binary')\n",
    "\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set model to evaluation mode ---\n",
    "DNN.eval()\n",
    "\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).float().unsqueeze(-1)\n",
    "\n",
    "        outputs = DNN(features)\n",
    "        preds = (outputs > 0.5).float()\n",
    "\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_outputs.append(outputs.cpu())\n",
    "\n",
    "# --- Concatenate all batches ---\n",
    "all_targets = torch.cat(all_targets).squeeze().long().numpy()  # integers 0/1\n",
    "all_preds = torch.cat(all_preds).squeeze().long().numpy()\n",
    "all_outputs = torch.cat(all_outputs).squeeze().numpy()             # floats in [0,1]\n",
    "\n",
    "# --- Sanity check ---\n",
    "print(all_targets.shape, all_preds.shape, all_outputs.shape)\n",
    "print(np.unique(all_targets))  # should be [0,1]\n",
    "\n",
    "# --- Compute Metrics ---\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "auc_score = roc_auc_score(all_targets, all_outputs)  # should work now\n",
    "f1 = f1_score(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "# Critical Success Index (CSI)\n",
    "tp = cm[1,1]\n",
    "fn = cm[1,0]\n",
    "fp = cm[0,1]\n",
    "csi = tp / (tp + fn + fp)\n",
    "\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}, CSI: {csi:.4f}\")\n",
    "\n",
    "# --- Plot Confusion Matrix ---\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "VALIDATION_FILE = '../Data/2025-Quantum-Tornado-validation_data-160-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_excel(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_excel(TEST_FILE)\n",
    "# Load validation data\n",
    "df_val = pd.read_excel(VALIDATION_FILE)\n",
    "\n",
    "# Quantum device and parameters\n",
    "n_qubits = 8\n",
    "n_layers = 1\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Using Random Layers PQC\n",
    "USE_RANDOM = True\n",
    "\n",
    "if USE_RANDOM:\n",
    "    # RandomLayers expects shape (n_layers, n_rotations_per_layer)\n",
    "    # For 8 qubits, each layer typically has 3 * 8 = 24 rotations\n",
    "    rand_params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits * 3))\n",
    "    n_qubits = 8\n",
    "    n_layers = 1\n",
    "    phi = nn.Parameter(torch.randn(n_layers, n_qubits, 9))\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "    def quantum_feature_embedding(f, phi):\n",
    "        qml.AngleEmbedding(features=f, wires=range(n_qubits))\n",
    "        RandomLayers(phi, wires=range(n_qubits), seed=6)\n",
    "        return qml.state()  # returns 2**n_qubits = 256-dim statevector\n",
    "\n",
    "# Using Strongly Entangling Layers\n",
    "else:\n",
    "    # StronglyEntanglingLayers expects shape (n_layers, n_wires, 3)\n",
    "    rand_params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits, 3))\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "    def quantum_feature_embedding(f, phi):\n",
    "        qml.AngleEmbedding(features=f, wires=range(n_qubits))\n",
    "        qml.StronglyEntanglingLayers(weights=phi, wires=range(n_qubits))\n",
    "        return qml.state()\n",
    "\n",
    "# Batched embedding helper\n",
    "def quantum_feature_embedding_batch(x_batch, phi, device=\"cuda\"):\n",
    "    \"\"\"Apply QNode to batch of inputs -> (B, 256)\"\"\"\n",
    "    outputs = []\n",
    "    phi = phi.detach().cpu()\n",
    "    for x in x_batch:\n",
    "        result = quantum_feature_embedding(x.detach().cpu(), phi)\n",
    "        outputs.append(result.real.to(device))\n",
    "    return torch.stack(outputs)\n",
    "\n",
    "# Test single example\n",
    "state = quantum_feature_embedding(\n",
    "    torch.tensor([1/4] * n_qubits, dtype=torch.float32),\n",
    "    torch.tensor(rand_params, dtype=torch.float32)\n",
    ")\n",
    "print(\"Single state shape:\", state.shape)  # (256,)\n",
    "\n",
    "# Test batch\n",
    "sample = torch.randn(16, n_qubits)\n",
    "phi_tensor = torch.tensor(rand_params, dtype=torch.float32)\n",
    "output = quantum_feature_embedding_batch(sample, phi_tensor, device = device)\n",
    "print(\"Batch output shape:\", output.shape)  # (16, 256)\n",
    "\n",
    "# Torch module for integration\n",
    "class QuantumFeatureEmbeddingBatch(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.phi = nn.Parameter(torch.tensor(\n",
    "            np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits * 3)), \n",
    "            dtype=torch.float32\n",
    "        ))\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        outputs = []\n",
    "        phi = self.phi.detach().cpu()\n",
    "        for x in x_batch:\n",
    "            result = quantum_feature_embedding(x.detach().cpu(), phi)\n",
    "            outputs.append(result.real.to(self.device))\n",
    "        return torch.stack(outputs)\n",
    "\n",
    "# Visualize\n",
    "qml.drawer.use_style('pennylane')\n",
    "fig, ax = qml.draw_mpl(quantum_feature_embedding, level=\"device\")(f=[1/4]*n_qubits, phi=rand_params)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass QNN with Quantum Random Layer feature encoder\n",
    "class MulticlassQNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encodes features from dataset\n",
    "        self.feature_encoder = QuantumFeatureEmbeddingBatch()\n",
    "\n",
    "        # Classifies based on encoded features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        feats_encoded = self.feature_encoder(features)\n",
    "        class_probs = self.classifier(feats_encoded.float())\n",
    "\n",
    "        return class_probs  # Shape: (batch_size, 1)\n",
    "    \n",
    "X_train, y_train, X_test, y_test, X_val, y_val = Preprocess(df_train, df_test, df_val, balance = 'smote', classes = 'multiclass')\n",
    "\n",
    "print(y_test[:])\n",
    "print(y_train[:])\n",
    "print(y_val[:])\n",
    "\n",
    "train_data = ClassificationDataset(X_train, y_train)\n",
    "validation_data = ClassificationDataset(X_val, y_val)\n",
    "test_data = ClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "DNN = MulticlassQNN().to(device)\n",
    "\n",
    "load_path = \"checkpoints/DNN_model_best_accuracy_RLMulti.pt\" # Path to load model\n",
    "\n",
    "checkpoint = torch.load(load_path, map_location= device)\n",
    "\n",
    "# Restore model weights\n",
    "DNN.load_state_dict(checkpoint[\"DNN_state_dict\"])\n",
    "    \n",
    "print(f\"Loaded model from {load_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN.eval()\n",
    "all_targets, all_preds, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():>\n",
    "    for features, target in test_loader:\n",
    "        features = features.to(device)\n",
    "        target = target.to(device).long()\n",
    "        outputs = DNN(features)\n",
    "        \n",
    "        if outputs.shape[1] == 1:\n",
    "            # Binary case\n",
    "            probs = torch.sigmoid(outputs).squeeze(-1)\n",
    "            preds = (probs > 0.5).long()\n",
    "        else:\n",
    "            # Multiclass case\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    ">\n",
    "        all_targets.append(target.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_probs.append(probs.cpu())\n",
    "\n",
    "# Concatenate\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "if outputs.shape[1] == 1:\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    auc_score = roc_auc_score(all_targets, all_probs)\n",
    "    csi = cm[1,1] / (cm[1,1] + cm[1,0] + cm[0,1])\n",
    "else:\n",
    "    num_classes = outputs.shape[1]\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_targets], all_probs, multi_class='ovr')\n",
    "    csi = []\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i,i]\n",
    "        fn = cm[i,:].sum() - tp\n",
    "        fp = cm[:,i].sum() - tp\n",
    "        csi.append(tp / (tp + fn + fp) if (tp+fn+fp)>0 else 0)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"AUC: {auc_score:.4f}, F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "if outputs.shape[1] > 1:\n",
    "    for i, c in enumerate(csi):\n",
    "        print(f\"Class {i} CSI: {c:.4f}\")\n",
    "else:\n",
    "    print(f\"CSI: {csi:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "plt.figure(figsize=(7,6))\n",
    "if outputs.shape[1] == 1:\n",
    "    fpr, tpr, _ = roc_curve(all_targets, all_probs)\n",
    "    plt.plot(fpr, tpr, label=f'AUC={auc_score:.4f}')\n",
    "else:\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve((all_targets==i).astype(int), all_probs[:,i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b019fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amaciejunes/Desktop/srnl/.venv/bin/python\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6449fd44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
