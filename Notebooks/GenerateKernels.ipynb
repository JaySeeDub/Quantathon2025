{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ebe0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Imports import *\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d75f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuAcceleration = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training data loaded: 69 rows, 8 columns\n",
      "✓ Test data loaded: 21 rows, 8 columns\n",
      "ef_class\n",
      "2    50\n",
      "3    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_dimension=8\n",
    "reps=5 #4 is a good number. 10 overfits.\n",
    "\n",
    "# Data paths\n",
    "TRAIN_FILE = '../Data/X_train_scaled.csv'\n",
    "TEST_FILE = '../Data/X_test_scaled.csv'\n",
    "LABEL_TRAIN_FILE = '../Data/2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "LABEL_TEST_FILE = '../Data/2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "SAVE_LOCATION = \"../kernels/\"\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "\n",
    "df_label_train_class = pd.read_excel(LABEL_TRAIN_FILE)[\"ef_class\"]\n",
    "\n",
    "df_label_test_class = pd.read_excel(LABEL_TEST_FILE)[\"ef_class\"]\n",
    "\n",
    "df_label_train_class, df_train = removeWeakTornados(df_label_train_class, df_train)\n",
    "df_label_test_class, df_test = removeWeakTornados(df_label_test_class, df_test)\n",
    "\n",
    "# Renormalize Data\n",
    "df_train = df_train.drop(df_train.columns[-1], axis = 1) \n",
    "df_train = np.tanh(df_train)\n",
    "df_test = df_test.drop(df_test.columns[-1], axis = 1)\n",
    "df_test = np.tanh(df_test)\n",
    "\n",
    "print(f\"✓ Training data loaded: {df_train.shape[0]} rows, {df_train.shape[1]} columns\")\n",
    "print(f\"✓ Test data loaded: {df_test.shape[0]} rows, {df_test.shape[1]} columns\")\n",
    "\n",
    "print(df_label_train_class.value_counts())\n",
    "#This training data is imbalanced; I need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf8f41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict of which Encodings/Kernels to compute.\n",
    "gammas = [50, 45, 40, 35, 30]\n",
    "\n",
    "encodingSettings = {\n",
    "    \"zzEncoding\":True,\n",
    "    \"zzEncoding_full_entangle\":True,\n",
    "    \"pauli_feature_map_full_entangle\":True\n",
    "}\n",
    "\n",
    "classicalKernelSettings = {\n",
    "    \"rbf\":True,\n",
    "    \"polynomial\":False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32849717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Encoding - Different Methods to try. \n",
    "#Make this a dict? Then settings choose which to include in dict. Makes training/fitting/faster\n",
    "feature_maps = {\n",
    "#basisEncoding = ,\n",
    "#amplitudeEncoding = ,\n",
    "#angleEncoding = ,\n",
    "#phaseEncoding = ,\n",
    "#denseAngleEncoding = ,\n",
    "\"zzEncoding\": zz_feature_map(feature_dimension=feature_dimension, reps=reps, entanglement=\"linear\"),\n",
    "\"zzEncoding_full_entangle\": zz_feature_map(feature_dimension=feature_dimension, reps=reps, entanglement=\"full\"),\n",
    "\"pauli_feature_map_full_entangle\": pauli_feature_map(feature_dimension=feature_dimension, reps=reps, entanglement=\"full\")\n",
    "}\n",
    "\n",
    "#what does varying reps do? Can I show a number on how varying reps changes things?\n",
    "#Print/store data like circuit depth!\n",
    "#Try different feature maps! Which is best?\n",
    "\n",
    "#Different inner products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "511ae8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing kernel for zzEncoding feature map\n",
      "computing kernel for zzEncoding_full_entangle feature map\n",
      "computing kernel for pauli_feature_map_full_entangle feature map\n"
     ]
    }
   ],
   "source": [
    "for encoding in feature_maps:\n",
    "    if encodingSettings[encoding]:\n",
    "        print(f\"computing kernel for {encoding} feature map\")\n",
    "        quantum_kernel = FidelityStatevectorKernel(feature_map=feature_maps[encoding])\n",
    "        quantum_kernel_train = quantum_kernel.evaluate(df_train)\n",
    "        quantum_kernel_test = quantum_kernel.evaluate(df_test, df_train)\n",
    "        np.save(f'./kernels/{encoding}_kernel_train.npy', quantum_kernel_train)\n",
    "        np.save(f'./kernels/{encoding}_kernel_test.npy', quantum_kernel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92cc5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel_train = {}\n",
    "rbf_kernel_test = {}\n",
    "\n",
    "if classicalKernelSettings[\"rbf\"]:\n",
    "    for gamma in gammas:\n",
    "        rbf_kernel_train[gamma] = rbf_kernel(df_train, gamma=gamma)\n",
    "        rbf_kernel_test[gamma] = rbf_kernel(df_test, df_train, gamma=gamma)\n",
    "        np.save(f'./kernels/rbf_gamma={gamma}_kernel_train.npy', rbf_kernel_train)\n",
    "        np.save(f'./kernels/rbf_gamma={gamma}_kernel_test.npy', rbf_kernel_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelEstimate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
