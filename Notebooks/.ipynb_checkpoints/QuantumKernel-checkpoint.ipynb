{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebe0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit.circuit.library import zz_feature_map\n",
    "from qiskit_aer.primitives import SamplerV2\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d75f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer.primitives import SamplerV2 as Sampler\n",
    "\n",
    "backend_options = {        \n",
    "    'device': \"GPU\",\n",
    "    }\n",
    "\n",
    "options = {\n",
    "    'backend_options': backend_options\n",
    "    }\n",
    "\n",
    "sampler = Sampler(options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training data loaded: 640 rows, 9 columns\n",
      "✓ Test data loaded: 200 rows, 9 columns\n"
     ]
    }
   ],
   "source": [
    "feature_dimension=8\n",
    "reps=2\n",
    "\n",
    "# Data paths\n",
    "TRAIN_FILE = '../Data/X_train_scaled.csv'\n",
    "TEST_FILE = '../Data/X_test_scaled.csv'\n",
    "LABEL_TRAIN_FILE = '../2025-Quantathon-Tornado-Q-training_data-640-examples.xlsx'\n",
    "LABEL_TEST_FILE = '../2025-Quantum-Tornado-Q-test_data-200-examples.xlsx'\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "# Load test data\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "\n",
    "df_label_train_binary = pd.read_excel(LABEL_TRAIN_FILE)[\"ef_binary\"]\n",
    "df_label_train_class = pd.read_excel(LABEL_TRAIN_FILE)[\"ef_class\"]\n",
    "\n",
    "df_test_train_binary = pd.read_excel(LABEL_TEST_FILE)[\"ef_binary\"]\n",
    "df_test_train_class = pd.read_excel(LABEL_TEST_FILE)[\"ef_class\"]\n",
    "\n",
    "print(f\"✓ Training data loaded: {df_train.shape[0]} rows, {df_train.shape[1]} columns\")\n",
    "print(f\"✓ Test data loaded: {df_test.shape[0]} rows, {df_test.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6a26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Public entry point: build a circuit that (1) encodes features\n",
    "# and (2) applies a configurable entangling block.\n",
    "# ------------------------------------------------------------\n",
    "from typing import Iterable, Sequence, Literal\n",
    "from qiskit import QuantumCircuit\n",
    "def build_circuit(\n",
    "    data: Iterable[float],\n",
    "    *,\n",
    "    # ---- Encoding controls ----\n",
    "    normalize: bool = True,\n",
    "    angle_scale: float = np.pi,                  # multiply angles by this (e.g., π)\n",
    "    encoding_axes: Sequence[str] = (\"rx\", \"ry\"), # which rotations to use per feature\n",
    "                                                 # e.g., (\"ry\",) or (\"ry\",\"rz\") etc.\n",
    "    # ---- Entangler controls ----\n",
    "    entanglement: Literal[\"full\", \"ring\", \"linear\"] = \"full\",\n",
    "    gate:        Literal[\"cx\", \"cz\"] = \"cx\",\n",
    "    num_layers:  int = 2,\n",
    "    alternate_directions: bool = True,\n",
    "    add_barriers: bool = True,\n",
    ") -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    Builds a feature-generating circuit for your shadows pipeline:\n",
    "      data -> [angle encoding] -> [entangling layers]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Iterable[float]\n",
    "        Your feature vector (one qubit per feature).\n",
    "    normalize : bool\n",
    "        Whether to apply tanh normalization (maps to [-1,1]) before angle scaling.\n",
    "        Recommended for robustness.\n",
    "    angle_scale : float\n",
    "        Scalar to multiply features when used as rotation angles (default π).\n",
    "    encoding_axes : Sequence[str]\n",
    "        Rotations to apply per feature, in order. Options: \"rx\", \"ry\", \"rz\".\n",
    "        Example: (\"ry\",) or (\"ry\",\"rz\") or (\"rx\",\"ry\",\"rz\").\n",
    "    entanglement : {\"full\",\"ring\",\"linear\"}\n",
    "        Connectivity of the entangling block.\n",
    "    gate : {\"cx\",\"cz\"}\n",
    "        Two-qubit gate family. Use \"cz\" if your backend favors symmetric CZ.\n",
    "    num_layers : int\n",
    "        Number of repeated entangling layers.\n",
    "    alternate_directions : bool\n",
    "        If using CX, flip control/target each layer to reduce directional bias.\n",
    "    add_barriers : bool\n",
    "        Add visual/compile barriers between layers (useful during debugging).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    QuantumCircuit\n",
    "        Circuit with encoding + entanglement applied.\n",
    "    \"\"\"\n",
    "    data = np.asarray(list(data), dtype=float)\n",
    "    n = int(data.size)\n",
    "    assert n >= 2, \"Need at least 2 qubits (features) to add entanglement.\"\n",
    "\n",
    "    # ---------- 1) Normalize & scale angles ----------\n",
    "    # Good default for continuous geophysical features (robust to outliers).\n",
    "    if normalize:\n",
    "        data = np.tanh(data)               # maps to [-1,1]\n",
    "    thetas = angle_scale * data            # rescale to angles\n",
    "\n",
    "    # ---------- 2) Encoding ----------\n",
    "    qc = QuantumCircuit(n, name=\"encode+entangle\")\n",
    "    _apply_angle_encoding(qc, thetas, encoding_axes)\n",
    "\n",
    "    # ---------- 3) Entangling block ----------\n",
    "    _add_entangling_layer(\n",
    "        qc,\n",
    "        num_layers=num_layers,\n",
    "        entanglement=entanglement,\n",
    "        gate=gate,\n",
    "        alternate_directions=alternate_directions,\n",
    "        add_barriers=add_barriers,\n",
    "    )\n",
    "    return qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deea2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renormalize Data\n",
    "\n",
    "df_train = df_train.drop(df_train.columns[-1], axis \n",
    "df_train = np.tanh(df_train)\n",
    "\n",
    "df_test = df_test.drop(df_test.columns[-1], axis = 1)\n",
    "df_test = np.tanh(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21022802-ac78-455f-bafc-c08e1fee0b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cape</th>\n",
       "      <th>cin</th>\n",
       "      <th>dewpoint_2m</th>\n",
       "      <th>temp_2m</th>\n",
       "      <th>tcwv</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>shear_0_1km</th>\n",
       "      <th>shear_0_3km</th>\n",
       "      <th>cin_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371538</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>0.458681</td>\n",
       "      <td>0.428780</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.463466</td>\n",
       "      <td>0.397877</td>\n",
       "      <td>0.387827</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.279775</td>\n",
       "      <td>0.440106</td>\n",
       "      <td>0.449629</td>\n",
       "      <td>0.196232</td>\n",
       "      <td>0.420655</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.156703</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416491</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.302210</td>\n",
       "      <td>0.467415</td>\n",
       "      <td>0.229141</td>\n",
       "      <td>0.205445</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414660</td>\n",
       "      <td>0.393765</td>\n",
       "      <td>0.180039</td>\n",
       "      <td>0.469032</td>\n",
       "      <td>0.366693</td>\n",
       "      <td>0.300338</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385056</td>\n",
       "      <td>0.366194</td>\n",
       "      <td>0.205322</td>\n",
       "      <td>0.456736</td>\n",
       "      <td>0.431352</td>\n",
       "      <td>0.145605</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211918</td>\n",
       "      <td>0.120926</td>\n",
       "      <td>0.030647</td>\n",
       "      <td>0.465196</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.050113</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.306263</td>\n",
       "      <td>0.468898</td>\n",
       "      <td>0.446536</td>\n",
       "      <td>0.454046</td>\n",
       "      <td>0.338060</td>\n",
       "      <td>0.436324</td>\n",
       "      <td>0.265455</td>\n",
       "      <td>0.149676</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.129926</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>0.455201</td>\n",
       "      <td>0.419567</td>\n",
       "      <td>0.358340</td>\n",
       "      <td>0.446148</td>\n",
       "      <td>0.227869</td>\n",
       "      <td>0.155072</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.384568</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.290035</td>\n",
       "      <td>0.010916</td>\n",
       "      <td>0.079816</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267673</td>\n",
       "      <td>0.415330</td>\n",
       "      <td>0.016859</td>\n",
       "      <td>0.449072</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>0.47198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cape       cin  dewpoint_2m   temp_2m      tcwv  surface_pressure  \\\n",
       "0    0.371538  0.185767     0.458681  0.428780  0.329352          0.463466   \n",
       "1    0.010658  0.279775     0.440106  0.449629  0.196232          0.420655   \n",
       "2    0.000000  0.000000     0.416491  0.419580  0.302210          0.467415   \n",
       "3    0.002496  0.000000     0.414660  0.393765  0.180039          0.469032   \n",
       "4    0.000000  0.000000     0.385056  0.366194  0.205322          0.456736   \n",
       "..        ...       ...          ...       ...       ...               ...   \n",
       "635  0.000005  0.000000     0.211918  0.120926  0.030647          0.465196   \n",
       "636  0.306263  0.468898     0.446536  0.454046  0.338060          0.436324   \n",
       "637  0.129926  0.263423     0.455201  0.419567  0.358340          0.446148   \n",
       "638  0.000517  0.000000     0.132653  0.384568  0.066541          0.290035   \n",
       "639  0.000000  0.000000     0.267673  0.415330  0.016859          0.449072   \n",
       "\n",
       "     shear_0_1km  shear_0_3km  cin_missing  \n",
       "0       0.397877     0.387827      0.00000  \n",
       "1       0.000087     0.156703      0.00000  \n",
       "2       0.229141     0.205445      0.47198  \n",
       "3       0.366693     0.300338      0.47198  \n",
       "4       0.431352     0.145605      0.47198  \n",
       "..           ...          ...          ...  \n",
       "635     0.183300     0.050113      0.47198  \n",
       "636     0.265455     0.149676      0.00000  \n",
       "637     0.227869     0.155072      0.00000  \n",
       "638     0.010916     0.079816      0.47198  \n",
       "639     0.063991     0.047547      0.47198  \n",
       "\n",
       "[640 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32849717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Encoding (zz)\n",
    "feature_map = zz_feature_map(feature_dimension=feature_dimension, reps=reps, entanglement=\"linear\")\n",
    "\n",
    "#Why this kind of data encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "927dbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Quantum Kernel\n",
    "quantum_kernel = FidelityQuantumKernel(feature_map=feature_map, fidelity=ComputeUncompute(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414b3505",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x_vec and class feature map have incompatible dimensions.\nx_vec has 9 dimensions, but feature map has 8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_machine_learning/kernels/base_kernel.py:114\u001b[0m, in \u001b[0;36mBaseKernel._validate_input\u001b[0;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_qubits\u001b[49m \u001b[38;5;241m=\u001b[39m x_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m a_e:\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute 'num_qubits'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Train the QSVC\u001b[39;00m\n\u001b[1;32m      3\u001b[0m qsvc \u001b[38;5;241m=\u001b[39m QSVC(quantum_kernel\u001b[38;5;241m=\u001b[39mquantum_kernel)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mqsvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_label_train_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m kernel_matrix_train \u001b[38;5;241m=\u001b[39m quantum_kernel\u001b[38;5;241m.\u001b[39mevaluate(df_train)  \u001b[38;5;66;03m# shape: (n_samples, n_samples)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m kernel_matrix_test \u001b[38;5;241m=\u001b[39m quantum_kernel\u001b[38;5;241m.\u001b[39mevaluate(df_test, df_train)  \u001b[38;5;66;03m# shape: (n_test, n_train)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:309\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# you must store a reference to X to compute the kernel in predict\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;66;03m# TODO: add keyword copy to copy on demand\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Xfit \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m--> 309\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[0] should be equal to X.shape[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:507\u001b[0m, in \u001b[0;36mBaseLibSVM._compute_kernel\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__Xfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(kernel):\n\u001b[1;32m    509\u001b[0m         kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py:101\u001b[0m, in \u001b[0;36mFidelityQuantumKernel.evaluate\u001b[0;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_vec: np\u001b[38;5;241m.\u001b[39mndarray, y_vec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 101\u001b[0m     x_vec, y_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# determine if calculating self inner product\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     is_symmetric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_machine_learning/kernels/base_kernel.py:116\u001b[0m, in \u001b[0;36mBaseKernel._validate_input\u001b[0;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_map\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;241m=\u001b[39m x_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m a_e:\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_vec and class feature map have incompatible dimensions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_vec has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut feature map has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ma_e\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     y_vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_vec)\n",
      "\u001b[0;31mValueError\u001b[0m: x_vec and class feature map have incompatible dimensions.\nx_vec has 9 dimensions, but feature map has 8."
     ]
    }
   ],
   "source": [
    "#Train the QSVC\n",
    "\n",
    "qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "qsvc.fit(df_train, df_label_train_binary)\n",
    "\n",
    "kernel_matrix_train = quantum_kernel.evaluate(df_train)  # shape: (n_samples, n_samples)\n",
    "kernel_matrix_test = quantum_kernel.evaluate(df_test, df_train)  # shape: (n_test, n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667effc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(kernel_matrix_train, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Kernel Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(kernel_matrix_test, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Test Matrix\")\n",
    "plt.show()\n",
    "\n",
    "score = qsvc.score(test_features, test_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96465f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Kernel Alignment\n",
    "#\n",
    "#measure of how well your kernel separates classes\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation with QSVC or Classical SVC\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab27262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare with Classical Kernels\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel Spectrum / Eigenvalues\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5391bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity Analysis\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
